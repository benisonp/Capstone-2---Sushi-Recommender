{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVD, NMF\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sushi = pd.read_csv('sushi3.idata', sep='\\t', names=['item_id', 'name', 'style', 'major_group', 'minor_group', \n",
    "                                                'oiliness', 'consumption_frequency', 'normalized_price',\n",
    "                                                'selling_frequency'])\n",
    "users = pd.read_csv('sushi3.udata', sep='\\t', names=['user_id', 'gender', 'age', 'survey_time', 'prefecture_15', \n",
    "                                                    'region_15','east/west_15', 'prefecture_now', 'region_now',\n",
    "                                                    'east/west_now', 'living_similarity'])\n",
    "set_b_sushi = sushi.name.unique()\n",
    "set_b_score = pd.read_csv('sushi3b.5000.10.score', sep=' ', names=set_b_sushi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 100)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ebi  anago  maguro  ika  uni  tako  ikura  tamago  toro  amaebi  \\\n",
      "user_id                                                                    \n",
      "6371     NaN    1.0     NaN  5.0  3.0   NaN    NaN     NaN   NaN     NaN   \n",
      "10007    NaN    NaN     NaN  NaN  NaN   NaN    1.0     NaN   2.0     NaN   \n",
      "1777     NaN    4.0     5.0  NaN  NaN   NaN    4.0     NaN   NaN     NaN   \n",
      "3613     5.0    NaN     NaN  4.0  5.0   2.0    NaN     NaN   5.0     4.0   \n",
      "8081     NaN    NaN     NaN  NaN  2.0   NaN    NaN     NaN   NaN     5.0   \n",
      "\n",
      "         ...   hoya  battera  kyabia  karasumi  uni_kurage  karei  hiramasa  \\\n",
      "user_id  ...                                                                  \n",
      "6371     ...    NaN      NaN     NaN       NaN         NaN    NaN       NaN   \n",
      "10007    ...    NaN      NaN     NaN       NaN         NaN    NaN       NaN   \n",
      "1777     ...    NaN      NaN     NaN       NaN         NaN    NaN       NaN   \n",
      "3613     ...    NaN      NaN     NaN       NaN         NaN    NaN       NaN   \n",
      "8081     ...    NaN      NaN     NaN       NaN         NaN    NaN       NaN   \n",
      "\n",
      "         namako  shishamo  kaki  \n",
      "user_id                          \n",
      "6371        NaN       NaN   NaN  \n",
      "10007       NaN       NaN   NaN  \n",
      "1777        NaN       NaN   NaN  \n",
      "3613        NaN       NaN   NaN  \n",
      "8081        NaN       NaN   1.0  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create dataset\n",
    "df_sparse = pd.concat([users['user_id'], set_b_score], axis=1)\n",
    "df_sparse = df_sparse.replace(-1, np.nan).set_index('user_id')\n",
    "# Redefine the rating scale to be from 1-5\n",
    "for col in df_sparse.columns:\n",
    "    df_sparse[col] = df_sparse[col].map({0.0:1.0, 1.0:2.0, 2.0:3.0, 3.0:4.0, 4.0:5.0})\n",
    "print(df_sparse.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe is 90.0% empty\n"
     ]
    }
   ],
   "source": [
    "#Calculate sparsity\n",
    "sparsity = df_sparse.isnull().sum().sum()*100/(df_sparse.shape[0] * df_sparse.shape[1])\n",
    "print(\"The dataframe is {}% empty\".format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     uid sushi  rating\n",
      "3   3613   ebi       5\n",
      "5   1462   ebi       5\n",
      "8   6861   ebi       5\n",
      "10  9077   ebi       1\n",
      "15  5281   ebi       4\n"
     ]
    }
   ],
   "source": [
    "# Convert the sparse dataframe from wide to long, dropping NaNs in the process\n",
    "df_sparse_original = df_sparse.reset_index()\n",
    "temp_df = pd.melt(df_sparse_original, id_vars=['user_id'], var_name='sushi', value_name='rating')\n",
    "temp_df.columns = ['uid', 'sushi', 'rating'] \n",
    "temp_df = temp_df.dropna()\n",
    "temp_df.rating = temp_df.rating.astype(int)\n",
    "print(temp_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_hyperparamters(method, param_grid, data):\n",
    "    '''\n",
    "    method: Chosen approach to the problem e.g. NMF or SVD\n",
    "    param_grid: The gridsearchcv parameter grid associated with the chosen method\n",
    "    data: The dataset used in this project; must have been a Surprise Dataset object \n",
    "    \n",
    "    Returns: Best parameters for the method, associated best RMSE score\n",
    "    '''\n",
    "    random.seed(42)\n",
    "    raw_ratings = data.raw_ratings\n",
    "    random.shuffle(raw_ratings)\n",
    "    # training data = 70% of the data, test data = 30% of the data\n",
    "    threshold = int(.7 * len(raw_ratings))\n",
    "    training_data = raw_ratings[:threshold]\n",
    "    test_data = raw_ratings[threshold:]\n",
    "    data.raw_ratings = training_data  # data is now the training_data\n",
    "    \n",
    "    algo_cv = GridSearchCV(method, param_grid, cv=3)\n",
    "    algo_cv.fit(data)\n",
    "    best_parameters = algo_cv.best_params['rmse']\n",
    "    best_score = algo_cv.best_score['rmse']\n",
    "    \n",
    "    return best_parameters, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-negative Matrix Factorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_factors': 25,\n",
       "  'n_epochs': 40,\n",
       "  'reg_pu': 0.08,\n",
       "  'reg_bu': 0.05,\n",
       "  'reg_bi': 0.04},\n",
       " 1.27662401932413)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(temp_df[['uid', 'sushi', 'rating']], reader)\n",
    "\n",
    "param_grid_NMF = {'n_factors': [5, 10, 15, 20, 25], 'n_epochs':[40, 50, 60],\n",
    "                 'reg_pu':list(np.arange(0.07,0.09,0.01)), 'reg_pu':list(np.arange(0.07,0.09,0.01)),\n",
    "                 'reg_bu':list(np.arange(0.03, 0.05,0.01)), 'reg_bi':list(np.arange(0.03,0.05,0.01))}\n",
    "best_model_hyperparamters(NMF, param_grid_NMF, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_nmf = NMF(n_factors=25, n_epochs=40, reg_pu=0.08, reg_bu=0.05, reg_bi=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_factors': 100, 'n_epochs': 20}, 1.177744070559631)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(temp_df[['uid', 'sushi', 'rating']], reader)\n",
    "\n",
    "param_grid_svd = {'n_factors': [90, 100, 110], 'n_epochs':[20,30,40]}\n",
    "\n",
    "best_model_hyperparamters(SVD, param_grid_svd, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_svd = SVD(n_factors=100, n_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rmse(algo_cv, data):\n",
    "    '''\n",
    "    Returns the RMSE score of a cross-validated model on the test set\n",
    "    \n",
    "    algo_cv: A cross-validated model with parameters entered (from GridSearchCV or RandomizedSearchCV) \n",
    "             e.g. NMF(n_factors=50)\n",
    "    data: The dataset used in this project; must have been a Surprise Dataset object \n",
    "    '''\n",
    "    import random\n",
    "    # Randomly shuffle ratings\n",
    "    random.seed(42)\n",
    "    raw_ratings = data.raw_ratings\n",
    "    random.shuffle(raw_ratings)\n",
    "    # training data = 70% of the data, test data = 30% of the data\n",
    "    threshold = int(.7 * len(raw_ratings))\n",
    "    training_data = raw_ratings[:threshold]\n",
    "    test_data = raw_ratings[threshold:]\n",
    "    data.raw_ratings = training_data  # data is now the training_data\n",
    "    # Training set\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo_cv.fit(trainset)\n",
    "\n",
    "    # Compute RMSE on test set\n",
    "    testset = data.construct_testset(test_data)  # construct testset\n",
    "    predictions = algo_cv.test(testset)\n",
    "    model_rmse = accuracy.rmse(predictions)\n",
    "    return(model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1595\n",
      "RMSE: 1.2899\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(temp_df[['uid', 'sushi', 'rating']], reader)\n",
    "\n",
    "svd_rmse = model_rmse(algo_svd, data)\n",
    "nmf_rmse = model_rmse(algo_nmf, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of the SVD model is : 1.159504599012967\n",
      "The RMSE of the NMF model is : 1.2899191155402001\n"
     ]
    }
   ],
   "source": [
    "print(\"The RMSE of the SVD model is : {}\".format(svd_rmse))\n",
    "print(\"The RMSE of the NMF model is : {}\".format(nmf_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions for individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to create functions which can return a list of the top 10 recommended sushi for a given individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a given user - Non-novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_user(algo, uid, n=10):\n",
    "    '''\n",
    "    Returns the top n recommendations for a user, INCLUDING sushi they are familiar with.\n",
    "    \n",
    "    n(int): The number of recommendations to show for each user. Default is 10. \n",
    "    \n",
    "    Returns:\n",
    "    A dataframe with sushi names as well as values for sushi ratings, either predicted by the model or previously known\n",
    "    from user data. The top 10 entries (as defined by highest ratings) are shown.\n",
    "    '''\n",
    "    \n",
    "    # Creating lists of predicted sushi ratings (based on the model) and sushi names\n",
    "    sushi_ratings = [algo.predict(uid=6185, iid=item)[3] for item in df_sparse.columns]\n",
    "    sushi_list = [item for item in df_sparse.columns]\n",
    "    _ = pd.DataFrame({'Name': sushi_list, 'Ratings':sushi_ratings})\n",
    "    _ = _.sort_values(by=['Ratings'], ascending=False).head(n=10)\n",
    "    \n",
    "    return(_.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a given user - Novel recommendations only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_user_novel(algo, uid, n=10):\n",
    "    '''\n",
    "    Returns the top n novel recommendations for a user i.e. NOT INCLUDING sushi they are familiar with.\n",
    "    \n",
    "    n(int): The number of recommendations to show for each user. Default is 10. \n",
    "    \n",
    "    Returns:\n",
    "    A dataframe with sushi names as well as values for sushi ratings, either predicted by the model or previously known\n",
    "    from user data. The top 10 entries (as defined by highest ratings) are shown.\n",
    "    '''\n",
    "    \n",
    "    # First, find sushi the user has already rated\n",
    "    user_rated_sushi = [item for item in temp_df[temp_df.uid==uid]['sushi']]\n",
    "    # List of sushi that the user has NOT rated\n",
    "    unrated_sushi = set(user_rated_sushi) ^ set(df_sparse.columns) # Returns the non-overlapping elements between two sets\n",
    "    \n",
    "    # Creating lists of predicted sushi ratings (based on the model) and sushi names\n",
    "    sushi_ratings = [algo.predict(uid=uid, iid=item)[3] for item in unrated_sushi] #[3] is the estimated rating \n",
    "    sushi_list = [item for item in unrated_sushi]\n",
    "    _ = pd.DataFrame({'Name': sushi_list, 'Ratings':sushi_ratings})\n",
    "    _ = _.sort_values(by=['Ratings'], ascending=False).head(n=10)\n",
    "    \n",
    "    return(_.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shiso_maki</td>\n",
       "      <td>3.293347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toro</td>\n",
       "      <td>3.170982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>botanebi</td>\n",
       "      <td>3.157127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chu_toro</td>\n",
       "      <td>3.153187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tarabagani</td>\n",
       "      <td>3.108594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kanpachi</td>\n",
       "      <td>3.079632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ebi</td>\n",
       "      <td>3.048903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>uni</td>\n",
       "      <td>3.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hotategai</td>\n",
       "      <td>2.998628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>negi_toro_maki</td>\n",
       "      <td>2.980982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name   Ratings\n",
       "0      shiso_maki  3.293347\n",
       "1            toro  3.170982\n",
       "2        botanebi  3.157127\n",
       "3        chu_toro  3.153187\n",
       "4      tarabagani  3.108594\n",
       "5        kanpachi  3.079632\n",
       "6             ebi  3.048903\n",
       "7             uni  3.001063\n",
       "8       hotategai  2.998628\n",
       "9  negi_toro_maki  2.980982"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_user(algo_svd, 6371)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maguro</td>\n",
       "      <td>4.499095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tarabagani</td>\n",
       "      <td>4.493927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kani</td>\n",
       "      <td>4.464559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hirame</td>\n",
       "      <td>4.428349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chu_toro</td>\n",
       "      <td>4.370267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negi_toro_maki</td>\n",
       "      <td>4.309677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ikura</td>\n",
       "      <td>4.307424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>samon</td>\n",
       "      <td>4.238509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kurumaebi</td>\n",
       "      <td>4.220072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>toro_samon</td>\n",
       "      <td>4.177591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name   Ratings\n",
       "0          maguro  4.499095\n",
       "1      tarabagani  4.493927\n",
       "2            kani  4.464559\n",
       "3          hirame  4.428349\n",
       "4        chu_toro  4.370267\n",
       "5  negi_toro_maki  4.309677\n",
       "6           ikura  4.307424\n",
       "7           samon  4.238509\n",
       "8       kurumaebi  4.220072\n",
       "9      toro_samon  4.177591"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_user_novel(algo_svd, 3613)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = NMF()\n",
    "# retrain on the whole set training data\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Compute RMSE on test set\n",
    "testset = data.construct_testset(test_data)  # construct testset\n",
    "predictions = algo.test(testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
